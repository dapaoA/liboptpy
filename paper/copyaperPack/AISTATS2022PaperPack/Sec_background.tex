\section{Background}
\subsection{Optimal Transport and Unbalanced Optimal Transport}
Given two histograms $\alpha \in \mathbbm{R}^{m}, \beta \in \mathbbm{R}^{n},$ For a cost matrix $C \in \mathbbm{R}^{m \times n}$, Optimal transport problem is trying to get a corresponding transport matrix $T \in \mathbbm{R}^{m \times n}$ that minimize the whole transport cost, which could be formulated as:
$$
\begin{aligned}
W(\alpha,\beta) := \min_{ \mathbf{T} \in \mathbb{R}_{+}^{n \times n},\mathbf{T} \mathbbm{1} = \alpha, \mathbf{T}^{T}\mathbbm{1} = \beta} \langle \C, \mathbf{T} \rangle 
\end{aligned}
$$

We can write it into a vector type, set $c,t \in \mathbbm{R}^{mn}$:
$$
\begin{aligned}
W(\alpha,\beta) := \min_{t \in \mathbb{R}_{+}^{n^2}, \mathbf{N}t = \alpha, \mathbf{M}t = \beta} c^{\tranT}t 
\end{aligned}
$$

$\mathbf{N} \in \mathbbm{R}^{m \times mn}, \mathbf{N} \in \mathbbm{R}^{n \times mn}$ are two matrix consisted with 0 and 1, listed in Appendix.A. We define $y = [\alpha, \beta]^{\tranT}$, the UOT problem add a penalty function for the historgrams: 
\begin{equation}
\label{eq:uot}
W(\alpha,\beta) := \min_{t \in \mathbb{R}_{+}^{mn}} c^{\tranT}t + D_h(\mathbf{X}t,y)
\end{equation}
$D_h$ is the Bregman divergence and $h$ is the norm, $\X = [\mathbf{M}^{\tranT} \mathbf{N}^{\tranT}]^{\tranT}$.

\subsection{Relationship with Lasso}
Lasso-like problem has a general formula as:
$$
\begin{aligned}
f(t) = g(t) + D_h(\X t,b), t\in \mathbbm{R}^{mn}
\end{aligned}
$$
When $g(t) = \lambda \|t\|$ and $D_h(\X t,b) = \|\X t-b\|_2^2$, this is the Euclid regression Lasso problem


\subsection{Dynamic Screening Framework}

We follow \cite{NEURIPS2021_7b5b23f4}'s framework to introduce about the whole dynamic screening technique for Lasso-like problem:
\begin{equation}
\label{eq:lassolike}
f(t) = g(t) + d(\X t)
\end{equation}

By Frenchel-Rockafellar Duality, we get the dual problem
\begin{thm}
 (Frenchel-Rockafellar Duality) If $d$ and $g$ are proper convex functions on $\mathbbm{R}^{m+n}$ and $\mathbbm{R}^{mn}$. Then we have the following:
 $$
\begin{aligned}
\min_t  g(t) + d(Xt) = \max_{\theta} -d^*(-\theta)-g^*(X^{\tranT}\theta)
\end{aligned}
$$
\end{thm}

Because the primal function $d$ is always convex, the dual function $d^*$ is concave. Assuming $d^*$ is an L-strongly concave problem. we design an area for any $\tilde{\theta}$ by the strongly concave property:

\begin{thm}\label{circle}
(L-strongly concave) Considering problem \ref{eq:lassolike}, if $d$ and $g$ are both convex, for $\forall \theta \in{R^{m+n}}$, we have the following:  
$$
\begin{aligned}
\theta \in \{\frac{L}{2}\|\theta-\tilde{\theta}\|_2^2+d^*(-\tilde{\theta}) \leq d^*(-\theta)\}
\end{aligned}
$$
\end{thm}
We know that the optimal solution for the dual problem $\hat{\theta}$ satisfied the inequality, so the set is not empty.
We can get the dual form of Lasso-like problem for some specific functions: 
\begin{lem}
For $d(\X t) = \frac{1}{2}\|\X t-y\|_2^2$, the dual Lasso problem has the following form:
$$
\begin{aligned}
d^*(-\theta) = \frac{1}{2}\|\theta\|_2^2-y^{\tranT}\theta
\end{aligned}
$$

$$
g^*(X^{\tranT}\theta) = \left\{
\begin{aligned}
0 \quad&\quad ( \forall t \quad\theta^{\tranT}Xt - g(t) \leq 0 )\\
\infty \quad&( \exists t \quad\theta^{\tranT}Xt - g(t) \leq 0 )
\end{aligned}
\right.
$$
\end{lem}





















