\section{Introduction}

Optimal Transfer (OT) has a long history in mathematics and has recently become prevalent due to its important role in the machine learning community for measuring distances between histograms. It has outperformed traditional methods in many different areas such as domain adaptation  \citep{7586038}, generative models \citep{arjovsky2017wasserstein},, graph machine learning \citep{NEURIPS2019_fdd5b16f} and natural language processing.  \citep{084adf2f555549c493e0331a00e4ecad} Its popularity is attributed to the introduction of Sinkhorn's algorithm for the entropy optimal transmission problem, \citep{NIPS2013_af21d0c9} which improves the computational speed of the OT problem from $\Theta (n^3)$ of Simplex's method to $\Theta (n^2)$. In order to extend the optimal transmission problem, which can only handle balanced samples, to a wider range of unbalanced samples. The unbalanced optimal transport (UOT) is created by modifying the restriction term to a penalty term. It has been used in several applications like computational biology\citep{SCHIEBINGER2019928} , machine learning \citep{DBLP:conf/aistats/JanatiCG19} and deep learning \citep{DBLP:conf/iclr/YangU19}. 

The UOT problem is a regularized version of Kantorovich formulation which replaced the equality constraints with penalty functions on the marginal distributions with a divergence. Entropy form can also be solved by the Sinkhorn algorithm. It has many advantages, for example its theoretical complexity is even better than OT problem \citep{DBLP:conf/icml/PhamLHPB20}, but it is not perfect, for example, its solution is always dense due to the KL penalty term and has a larger error compared with other regularizers \citep{DBLP:conf/aistats/BlondelSR18}, which also brings some difficulties to many researches and applications. For this reason, many scholars have proposed other penalty terms for the UOT problem, such as $L_2$ and $L_1$ e.g. New problems have brought new solvers, such as FISTA, Majorization-Minimization method and Lagrange pairwise method. \citep{NEURIPS2021_c3c617a9} This is because the UOT problem has a similar structure to many other well-known problems such as non-negative matrix decomposition and Lasso problem, which encourages researchers to improve it by using the rich results in these fields.

Screening is a well-known technique promoted by \citep{ghaoui2010safe} in the field of lasso problems, where the penalty function of $L_1$ leads to a sparse solution of the problem, which can preselect solutions that must be zero by theory and freeze them before computation. The solutions of many large-scale optimization problems are sparse, and a large amount of computation is wasted on updating the zero elements. With the safe screening method, we can identify and freeze the elements that are zero before enabling the algorithm with linear complexity, thus saving optimization time. Screening method got  attention in recent years and have promoted a lot, such as Dynamic Screening \citep{7128732}, Gap screening method \citep{JMLR:v18:16-577} and Dynamic Sasvi \citep{NEURIPS2021_7b5b23f4}

Fortunately, the OT function in the UOT problem has the same effectiveness as $L_1$ in lasso, making the solution of the optimal problem always sparse. We believe that this means that the screening method that works in the Lasso problem can be applied to the UOT problem and, due to the unique structure of the UOT problem, will work better.


\textbf{Contribution}: 
\begin{itemize}
\item We systematically provide the framework for Screening method on UOT problem. We give the correct projection method for UOT screening, which is better than the Lasso one. 
\item We promoted a two plane screening method for UOT problems, which benefits from its sparse constraints and outperforms the ordinary methods.
\end{itemize}



