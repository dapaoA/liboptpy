\section{BACKGROUND}
\subsection{Optimal Transport and Unbalanced Optimal Transport}
Given two histograms $\vec{a}\in \R^{m}, \vec{b} \in \R^{n},$ For a cost matrix $\mat{C} \in \mathbbm{R_{+}}^{m \times n}$, mordern Optimal transport problem is trying to get a corresponding transport matrix $\mat{T} \in \R_{+}^{m \times n}$ that minimize the whole transport cost, which could be formulated as:
\begin{equation}
\begin{split}
&\operatorname{OT}(\vec{a},\vec{b}) := \min_{ \mat{T} \in \R_{+}^{m \times n}} \langle \mat{C}, \mat{T} \rangle \\
& \mat{T} \one_n= \vec{a}, \mat{T}^{T}\one_m = \vec{b}
\end{split}
\end{equation}

We can write it into a vector type, set $\vec{c},\vec{t} \in \mathbbm{R}^{mn}$:
\begin{equation}
\begin{split}
&\operatorname{OT}(\vec{a},\vec{b}) := \min_{\vec{t} \in \R_{+}^{n^2}} \vec{c}^{\tranT}\vec{t} \\
& \mat{N}\vec{t} = \vec{a}, \mat{M}\vec{t} = \vec{b}
\end{split}
\end{equation}

$\mat{N} \in \R^{m \times mn}, \mat{N} \in \R^{n \times mn}$ are two matrix consisted with 0 and 1, when $m=n=3$, 

\begin{equation}
\begin{split}
\mat{N}&=\begin{pmatrix}
1&1&1& & & & & &\\
 & & &1&1&1& & &\\
 & & & & & &1&1&1\\
\end{pmatrix}\\
\mat{M}&=\begin{pmatrix}
 1& & &1& & &1& &\\
 &1& & &1& & &1&\\
 & &1& & &1& & &1\\
 \end{pmatrix}
  \end{split}
 \end{equation}
When the $\|\vec{a}\|_2 = \|\vec{b}\|_2$, it is the OT problem. When $\|\vec{a}\|_2 \neq \|\vec{b}\|_2$, the solution $\hat{\vec{t}}$ is not exist. We define $\vec{y} = [\vec{a}, \vec{b}]^{\tranT}$, the UOT problem uses a penalty function for the historgrams: 
\begin{equation}
\label{eq:uot}
\operatorname{UOT}(\vec{a},\vec{b}) := \min_{\vec{t} \in \R_{+}^{mn}} \vec{c}^{\tranT}\vec{t} + D_h(\mat{X}\vec{t},\vec{y})
\end{equation}
$D_h$ is the Bregman divergence derived from the norm $h$, $\mat{X} = [\mat{M}^{\tranT} \mat{N}^{\tranT}]^{\tranT}$. 

\subsection{Relationship with Lasso}
The lasso-like problem has a general formula:
$$
\begin{aligned}
f(\vec{t}) = g(\vec{t}) + D_h(\mat{X} \vec{t},\vec{y}), t\in \mathbbm{R}^{mn}
\end{aligned}
$$
When $g(\vec{t}) = \lambda \|\vec{t}\|_1$ and $D_h(\mat{X} \vec{t},\vec{y}) = \|\mat{X} \vec{t}-\vec{y}\|_2^2$, this is the $L_2$ regression Lasso problem. It is important to note that $\mat{X}$ in UOT is a bit different from the $\mat{X}$ in the Lasso problem, the former $\mat{X}$ has a specific structure and has only two non-zero elements and is equal to 1, which is quite different to the irregular and dense $\mat{X}$ in Lasso problem.


\subsection{Dynamic Screening Framework}

We follow \citep{NEURIPS2021_7b5b23f4}'s framework to introduce the whole dynamic screening technique for the Lasso-like problem:
\begin{equation}
\label{eq:lassolike}
f(\vec{t}) = g(\vec{t}) + d(\mat{X} \vec{t})
\end{equation}

By Frenchel-Rockafellar Duality, we get the dual problem
\begin{thm}
 (Frenchel-Rockafellar Duality) If $d$ and $g$ are proper convex functions on $\mathbbm{R}^{m+n}$ and $\mathbbm{R}^{mn}$. Then we have the following:
 $$
\begin{aligned}
\min_\vec{t} g(\vec{t}) + d(\mat{X}\vec{t}) = \max_{\theta} -d^*(-\theta)-g^*(\mat{X}^{\tranT}\theta)
\end{aligned}
$$
\end{thm}

Because the primal function $d$ is always convex, the dual function $d^*$ is concave. Assuming $d^*$ is an L-strongly concave problem. we can design an area for any feasible $\tilde{\theta}$ by the strongly concave property:

\begin{thm}\label{circle}
(L-strongly concave) Considering problem \ref{eq:lassolike}, if function $d$ and $g$ are both convex, for $\forall \tilde{\theta} \in{R^{m+n}}$ and satisfied the constraints on the dual problem, we have the following area constructed by its L-strongly concave property:  
$$
\begin{aligned}
\mathcal{R}^{C}:=\theta \in \{\frac{L}{2}\|\theta-\tilde{\theta}\|_2^2+d^*(-\tilde{\theta}) \leq d^*(-\theta)\}
\end{aligned}
$$
\end{thm}
We know that the optimal solution for the dual problem $\hat{\theta}$ satisfied the inequality, so the set is not empty.





